# pykili_project

### Описание ###

Лингвистическое исследование на основе собранного вручную корпуса

### Как работает код и как его запускать ###

1. extract_texts.py - принимает папку с файлами, извлекает тексты и года из книг (txt) и архивов чатов ВК (html) и Телеграм (json), сам сортирует файлы в зависимости от расширения, возвращает списки сообщений с годами отправки
2. parser.py - принимает файл в формате json из предыдущего шага и делает морфологическую разметку каждого слова, возвращает также json
3. connector.py - принимает папку с фалами json, может соединить несколько файлов с морфологической разметкой из пункта (2) или несколько файлов с распределением прилагательных из пункта (4), возвращает один файл json
4. research_1.py
5. research_2.py

### Текущие задачи ###

- добавить комментарии к коду
- выводы по исследованию

### План проекта ###

1. Собрать данные, опросить знакомых, обкачать паблики: 
    - чаты мессенджеров 
        - проблема: авторское право, конфиденциальность личных данных
    - книги в эпистолярном жанре

2. Написать код дбработки данных, конкретно для извлечения текстов и извлечения годов:
    - книги в формате txt
    - телеграм чаты в формате json
    - ВК чаты в формате html
        - проблема: ну знаете регулрку напишешь, а потом окажется, что все равно нашел не все, поэтому регулярки совершенствовались по мере нахождения новых штук
        - проблема: баг с регуляркой для дат, довольно хитрый, пробую решить
3. Морфопарсер, написать код, создающий список слов с морфологическим разбором (начальной формой, частью речи, некоторыми грамматическими категориями, имеющими значениями для именных категорий, т.е. существительных и прилагательных: падеж, число, род)
    - проблема: опечатки, несуществующие слова, сленг (например, "лол кек" вообще непонятно как парсить)
    - решение: если останутся время силы, можно сделать базу данных наиболее популярных штук, которые нельзя распарсить стандартным парсером, например регулярками находить все варианты "ахахах", "пфф" или те же "лол кек"
4. Лингвистическое исследование, написать несколько алгоритмов сортировки распарсенных данных:
    - Анализ сочетаемости прилагательных с существительными
        - проблема: сложность с обработкой большого количества данных
        - решение: разбиение на части, дополнительный код, соединяющий части вместе
        - проблема: хотя наш алгоритм действительно находит достаточно много прилагательных к существительным, но свободный порядок слов в русском языке мешает найти все случаи
    - Подсчет количества частей речи по годам в процентах
    - Список частотных слов по годам
5. Создание графиков на основе полученных данных

### Используемые модули ###

- os
- re
- json
- string
- pymorphy

### Участники ###

- Софья Шакирова, БКЛ-202
- Полина Карпова, БКЛ-204
- Татьяна Ковтун, БКЛ-204
